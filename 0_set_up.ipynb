{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Part 0\n",
    "\n",
    "This notebook explains how to install all the preriquistes and libraries that you will need to run the following tutorials. If you can execute all the following cells, you are good to go.\n",
    "\n",
    "## Environment configuration\n",
    "\n",
    "\n",
    "### Install conda\n",
    "\n",
    "There are two major package managers in Python: pip and conda. For this tutorial we will be using conda which, besides being a package manager is also useful as a version manager. There are two main ways to install conda: Anaconda and Miniconda. Any will be useful for this course, just follow instructions here, according to your operative system:\n",
    "\n",
    "https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html#regular-installation\n",
    "\n",
    "### Create an environment with all the Anaconda libraries\n",
    "\n",
    "    $ conda create --name deeplearning python=3.7 anaconda\n",
    "\n",
    "Don't forget to activate the new env\n",
    "\n",
    "    $ conda activate deeplearning    \n",
    "\n",
    "### Install TensorFlow\n",
    "\n",
    "We will use the [TensorFlow](https://www.tensorflow.org/) library to build and train models. In particular, we will use [Keras](https://www.tensorflow.org/guide/keras) module, which are simpler to implement and understand, at the cost of lossing flexibility when defining the architectures.\n",
    "\n",
    "In order to install tensorflow we recommend following the [official documentation](https://www.tensorflow.org/install). In your local machine, you will install the version that only has cpu support, but in Nabucodonosor you need to install the version with [GPU support](https://www.tensorflow.org/install/gpu).\n",
    "\n",
    "#### CPU\n",
    "\n",
    "Upgrade `pip` to the latest version:\n",
    "\n",
    "    (deeplearning) $ pip install --upgrade pip\n",
    "\n",
    "Install tensorflow:\n",
    "\n",
    "    (deeplearning) $ pip install --upgrade tensorflow\n",
    "    \n",
    "Then just check the version installed is 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/mramirez/AprendizajeProfundo\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "#### GPU\n",
    "\n",
    "The supported version of Tensorlfow depends on the cuda drivers intalled on the machine. In the case of Nabucodonosor, cuda and cudnn libraries are located in the /opt directory. You can check the system has intalled cuda 10.X, and cuddnn >= 7.4.1, enough to intall tensorflow 2.0.\n",
    "\n",
    "    (deeplearning) $ pip install tensorflow-gpu\n",
    "\n",
    "**WARNING**: changes between tensorflow and keras versions are not minor and your code will break if you don't migrate. For example: https://www.tensorflow.org/beta/guide/effective_tf2\n",
    "\n",
    "Now we need to tell tensorflow where cuda is installed by setting the environment variable LD_LIBRARY_PATH\n",
    "\n",
    "    $ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/cuda/10.0/lib64:/opt/cudnn/v7.6-cu10.0/\n",
    "    $ export CUDA_HOME=/opt/cuda/10.0\n",
    "\n",
    "It is convenient to add this statement to your `~/.bashrc` file, so it is executed everytime you open a new console.\n",
    "\n",
    "To check if it works, execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install other libraries\n",
    "\n",
    "We need the `gensim` library to deal with word embeddings, so you need to install it. Plus, the `mlflow` tool to keep track of experiments. Also, for seeing a graphical representation of the Keras models, you need `graphviz` and `pydot`.\n",
    "\n",
    "\n",
    "```\n",
    "(deeplearning) $ pip install gensim mlflow\n",
    "(deeplearning) $ conda install graphviz python-graphviz pydot\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /users/mramirez/venv/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied: mlflow in /users/mramirez/venv/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: graphviz in /users/mramirez/venv/lib/python3.7/site-packages (0.13)\n",
      "Requirement already satisfied: pydot in /users/mramirez/venv/lib/python3.7/site-packages (1.4.1)\n",
      "Collecting nltk\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /users/mramirez/venv/lib/python3.7/site-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /users/mramirez/venv/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /users/mramirez/venv/lib/python3.7/site-packages (from gensim) (1.8.4)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /users/mramirez/venv/lib/python3.7/site-packages (from gensim) (1.17.2)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (2.8.0)\n",
      "Requirement already satisfied: sqlparse in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (0.3.0)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (0.9.0)\n",
      "Requirement already satisfied: gorilla in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (0.3.0)\n",
      "Requirement already satisfied: querystring-parser in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: sqlalchemy in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (1.3.10)\n",
      "Requirement already satisfied: docker>=4.0.0 in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (4.1.0)\n",
      "Requirement already satisfied: pyyaml in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (5.1.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (3.10.0)\n",
      "Requirement already satisfied: cloudpickle in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (1.2.2)\n",
      "Requirement already satisfied: Flask in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (1.1.1)\n",
      "Requirement already satisfied: simplejson in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (3.16.0)\n",
      "Requirement already satisfied: entrypoints in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (19.9.0)\n",
      "Requirement already satisfied: click>=7.0 in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (7.0)\n",
      "Requirement already satisfied: pandas in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (0.25.1)\n",
      "Requirement already satisfied: alembic in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.17.3 in /users/mramirez/venv/lib/python3.7/site-packages (from mlflow) (2.22.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /users/mramirez/venv/lib/python3.7/site-packages (from pydot) (2.4.2)\n",
      "Requirement already satisfied: boto>=2.32 in /users/mramirez/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /users/mramirez/venv/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.9.248)\n",
      "Requirement already satisfied: gitdb2>=2.0.0 in /users/mramirez/venv/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow) (2.0.6)\n",
      "Requirement already satisfied: configparser>=0.3.5 in /users/mramirez/venv/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (4.0.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /users/mramirez/venv/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.5)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /users/mramirez/venv/lib/python3.7/site-packages (from docker>=4.0.0->mlflow) (0.56.0)\n",
      "Requirement already satisfied: setuptools in /users/mramirez/venv/lib/python3.7/site-packages (from protobuf>=3.6.0->mlflow) (41.4.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /users/mramirez/venv/lib/python3.7/site-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /users/mramirez/venv/lib/python3.7/site-packages (from Flask->mlflow) (0.16.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /users/mramirez/venv/lib/python3.7/site-packages (from Flask->mlflow) (2.10.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /users/mramirez/venv/lib/python3.7/site-packages (from pandas->mlflow) (2019.3)\n",
      "Requirement already satisfied: python-editor>=0.3 in /users/mramirez/venv/lib/python3.7/site-packages (from alembic->mlflow) (1.0.4)\n",
      "Requirement already satisfied: Mako in /users/mramirez/venv/lib/python3.7/site-packages (from alembic->mlflow) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/mramirez/venv/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /users/mramirez/venv/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /users/mramirez/venv/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /users/mramirez/venv/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /users/mramirez/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.248 in /users/mramirez/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.248)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /users/mramirez/venv/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: smmap2>=2.0.0 in /users/mramirez/venv/lib/python3.7/site-packages (from gitdb2>=2.0.0->gitpython>=2.1.0->mlflow) (2.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /users/mramirez/venv/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /users/mramirez/venv/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.248->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449909 sha256=9fbe0ff2464b4c98a243f056b00650c710f731fb631466d35e13620d561a685b\n",
      "  Stored in directory: /users/mramirez/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install gensim mlflow graphviz pydot nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download embeddings and dataset\n",
    "\n",
    "### MNIST\n",
    "\n",
    "The dataset we will use (MNIST) will be downloaded by Keras automatically the first time you use it. To save time, you can download it now running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "df = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PetFinder Dataset\n",
    "\n",
    "For this course we will setup a Kaggle competition based on the same data for the course of \"Supervised Learning\". You can access the competition with [this link](https://www.kaggle.com/t/8842af91604944a9974bd6d5a3e097c5) and download the dataset (check the **Download All** button).\n",
    "\n",
    "Once you have the dataset downloaded in your machine you can copy it to `nabucodonosor` with the following command (this assumes you are already in the directory having the dataset):\n",
    "\n",
    "    $ scp diplodatos-deeplearning-2019.zip USERNAME@nabucodonosor.ccad.unc.edu.ar:./\n",
    "\n",
    "After that you should enter to nabucodonosor (via ssh) and unzip it like so:\n",
    "\n",
    "    $ unzip -d petfinder_dataset diplodatos-deeplearning-2019.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunneling and ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do you run a notebook in a remote machine?** You use an ssh connection with a port forwarding. This way, everything that goes to the port on the server machine (like a jupyter notebook) also goes to your localhost.\n",
    "\n",
    "It is likely that everyone will be using the same ports, so we recommend you to select a random number before connecting. The port on the ssh must be the same that you use to start the notebook.\n",
    "\n",
    "```\n",
    "$ ssh -L PORT:localhost:PORT USER@SERVER\n",
    "$ conda activate diplodatos\n",
    "(diplodatos) $ jupyter notebook --port PORT --no-browser\n",
    "```\n",
    "\n",
    "Now you can use the notebook as if it were running on your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using slurm\n",
    "\n",
    "The Nabucodonosor server uses a queue system called slurm, which grants exclusive access to the CPU resources. You should enqueue everythin you do that takes more than 10 minutes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up\n",
    "\n",
    "1. Download the script https://raw.githubusercontent.com/MIREL-UNC/mirel-scripts/master/run_scripts/submit_job_slurm.sh\n",
    "\n",
    "2. Create a logs folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enqueue things\n",
    "\n",
    "To enqueue a job on slurm, first put your command in a file, for example command.txt\n",
    "```\n",
    "$ sbatch submit_job_slurm.sh commant.txt\n",
    "```\n",
    "\n",
    "The queue will assign your job a number JOBID. All the output of your process will be redirected to logs/JOBID.out and logs/JOBID.err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controlling things\n",
    "\n",
    "To see the state of the queue run `$ squeue`\n",
    "\n",
    "To cancel a job run `$ scancel JOBID`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid using GPUs\n",
    "\n",
    "If all the GPUs are being used, you can still force Keras to use the CPU. For simple models this is still a very good option.\n",
    "\n",
    "The easiest way is to run set the environment variable  `CUDA_VISIBLE_DEVICES=\"\"` when running your commands. For example:\n",
    "\n",
    "```\n",
    "(diplodatos) $ CUDA_VISIBLE_DEVICES=\"\" jupyter notebook --no-browser\n",
    "(diplodatos) $ CUDA_VISIBLE_DEVICES=\"\" exercise_1.py --experiment_name mlp_200\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
